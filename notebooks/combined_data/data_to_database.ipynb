{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path setup\n",
    "import sys\n",
    "import os\n",
    "module_path = os.path.abspath(os.path.join('../../'))\n",
    "sys.path.insert(1, module_path + \"/utils\")\n",
    "\n",
    "## db setup\n",
    "# pip install sqlalchemy\n",
    "from sqlalchemy import create_engine, text\n",
    "from getpass import getpass \n",
    "\n",
    "import pandas as pd\n",
    "from data_processing import preprocess_climate_data, preprocess_shelter_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "password = getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### crate new db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the engine \n",
    "db_connection_string = 'mysql+pymysql://root:'+password+'@localhost/'\n",
    "engine = create_engine(db_connection_string)\n",
    "\n",
    "# connection to the MySQL server\n",
    "conn = engine.connect()\n",
    "\n",
    "# define db_name\n",
    "database_name = 'shelter'\n",
    "\n",
    "# drop the table if it exists\n",
    "drop_table_query = text(f\"DROP DATABASE IF EXISTS {database_name}\")\n",
    "conn.execute(drop_table_query)\n",
    "\n",
    "# create a new database\n",
    "create_db_query = text(f\"CREATE DATABASE IF NOT EXISTS {database_name}\")\n",
    "conn.execute(create_db_query)\n",
    "\n",
    "# update the database connection string\n",
    "db_connection_string = f'mysql+pymysql://root:{password}@localhost/{database_name}'\n",
    "\n",
    "# connect to the new database\n",
    "engine = create_engine(db_connection_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write data to db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_url = '../../data/raw/climate/climate-toronto2021-Q1-2024.csv'\n",
    "climate_df = preprocess_climate_data(climate_url)\n",
    "\n",
    "shelter_folder = '../../data/raw/shelter/'\n",
    "shelter_files = [os.path.join(shelter_folder, file) for file in os.listdir(shelter_folder) if file.endswith('.csv')]\n",
    "shelter_df = preprocess_shelter_data(shelter_files)\n",
    "\n",
    "shelter_climate = pd.merge(shelter_df, climate_df, on='date', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### write climate to db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1186"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "climate_df.to_sql('climate', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### write shelter to db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128349"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shelter_df.to_sql('shelter', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### write shelter_climate to db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128349"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shelter_climate.to_sql('shelter_climate', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### write daily_aggregations in toronto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pr/f4jl4tln3yn9fd_1yjrwwkp40000gn/T/ipykernel_83214/2810671742.py:21: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  daily['date'] = pd.to_datetime(daily['date'])\n"
     ]
    }
   ],
   "source": [
    "daily = shelter_climate.copy()\n",
    "daily = daily[daily['location_city'] == 'Toronto']\n",
    "daily['capacity_units'] = daily['taken_units'] + daily['free_units']\n",
    "\n",
    "agg_functions = {\n",
    "    'taken_units': 'sum',\n",
    "    'free_units': 'sum',\n",
    "    'capacity_units': 'sum',\n",
    "    'min_temperature': 'mean',\n",
    "    'total_precipitation': 'mean',\n",
    "    'mean_temperature': 'mean',\n",
    "    'max_temperature': 'mean',\n",
    "    'snow_on_ground': 'mean'\n",
    "}\n",
    "\n",
    "daily = daily.groupby('date').agg(agg_functions).reset_index()\n",
    "daily.columns = ['date', 'total_taken_units', 'total_free_units', 'total_capacity_units',\n",
    "                    'avg_min_temperature', 'avg_total_precipitation', 'avg_mean_temperature',\n",
    "                    'avg_max_temperature', 'avg_snow_on_ground']\n",
    "\n",
    "daily['date'] = pd.to_datetime(daily['date'])\n",
    "daily.dtypes\n",
    "\n",
    "daily = daily.sort_values(by='date')\n",
    "daily.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1186"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily.to_sql('daily_toronto', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily.to_csv(\"../../data/processed/daily_toronto.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### closing connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# closing the connection\n",
    "engine.dispose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
